{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58987b0",
   "metadata": {},
   "source": [
    "## In this notebook we are going to perform and test different types of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c9c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ecc4d",
   "metadata": {},
   "source": [
    "Here we will use the advertising dataset in order to perform the classic K-Fold cross-validation and test how well this function splits the data.\n",
    "<br></br>\n",
    "The first thing we have to do is to create the KFold object and split the data into two subsets: train and test sets with the purpose of performing cross validation only in the train set and validate just once in the test set and thus avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadb5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c82caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data.drop(\"sales\",axis=1),data['sales'],\n",
    "                                                 test_size = 0.2, random_state=97)\n",
    "#We zip this preprocessing and modelling steps in a pipeline\n",
    "pipe = Pipeline([(\"scaler\",StandardScaler()),(\"model\",LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c24d599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,   4,   6,   7,   8,   9,  10,  11,  13,  14,  15,  17,\n",
       "        18,  19,  21,  23,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
       "        34,  35,  36,  39,  40,  41,  42,  43,  44,  46,  48,  50,  51,\n",
       "        52,  53,  54,  57,  59,  60,  61,  62,  64,  66,  67,  69,  70,\n",
       "        71,  72,  73,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
       "        86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  98, 100, 101,\n",
       "       102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 120, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133,\n",
       "       134, 135, 136, 137, 139, 142, 143, 144, 147, 148, 149, 150, 151,\n",
       "       152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165,\n",
       "       166, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181,\n",
       "       182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the index of the train set rows\n",
    "np.sort(X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29afe56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8368030348383042,\n",
       "  0.825623080292534,\n",
       "  0.8967243723102103,\n",
       "  0.8933323393255432,\n",
       "  0.9161489573583848],\n",
       " [2.771159373302651,\n",
       "  4.689293378364903,\n",
       "  2.7620905257466006,\n",
       "  3.208287188848609,\n",
       "  2.0347036886053127])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform k-fold cross validation for each fold of the train set\n",
    "scores = []\n",
    "mean_sq = []\n",
    "for train, test in kf.split(X = X_train, y = y_train):\n",
    "    pipe.fit(X_train.iloc[train],y_train.iloc[train])\n",
    "    #get scores and save into an array\n",
    "    preds = pipe.predict(X_train.iloc[test])\n",
    "    errors = mean_squared_error(y_train.iloc[test], preds)\n",
    "    score = pipe.score(X_train.iloc[test], y_train.iloc[test])\n",
    "    scores.append(score)\n",
    "    mean_sq.append(errors)\n",
    "\n",
    "(scores,mean_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cf809",
   "metadata": {},
   "source": [
    "Let's stop for a moment and check what is KFold object returning:\n",
    "<br></br>\n",
    "First we run this loop over the KFold object enumerated (using the enumerate function).\n",
    "Then we call the split function of the KFold object in order to get the splits (on the entire dataset, which is not a good practice, we do this here just for practical purpose) for each iteration.\n",
    "Finally, we will show the splits which consist in two arrays (train fold and test fold).\n",
    "<br></br>\n",
    "Something to keep in mind is that the indexes returned are the \"intrinsic\" location of the rows and not their indexes in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb410bb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration: 0\n",
      "train set:\n",
      "[ 40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57\n",
      "  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
      " 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165\n",
      " 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
      "\n",
      "test set:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "train set: 160\n",
      "test set: 40\n",
      "\n",
      "iteration: 1\n",
      "train set:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
      " 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165\n",
      " 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
      "\n",
      "test set:\n",
      "[40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63\n",
      " 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79]\n",
      "train set: 160\n",
      "test set: 40\n",
      "\n",
      "iteration: 2\n",
      "train set:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
      " 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165\n",
      " 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
      "\n",
      "test set:\n",
      "[ 80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115\n",
      " 116 117 118 119]\n",
      "train set: 160\n",
      "test set: 40\n",
      "\n",
      "iteration: 3\n",
      "train set:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 160 161 162 163 164 165\n",
      " 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
      "\n",
      "test set:\n",
      "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159]\n",
      "train set: 160\n",
      "test set: 40\n",
      "\n",
      "iteration: 4\n",
      "train set:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]\n",
      "\n",
      "test set:\n",
      "[160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177\n",
      " 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195\n",
      " 196 197 198 199]\n",
      "train set: 160\n",
      "test set: 40\n"
     ]
    }
   ],
   "source": [
    "for index, (train, test) in enumerate(kf.split(X = data[['TV','radio','newspaper']], y = data['sales'])):\n",
    "    print('\\niteration: {0}\\ntrain set:\\n{1}\\n\\ntest set:\\n{2}'.format(index, train, test))\n",
    "    print('train set: {0}\\ntest set: {1}'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d4bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b21fa",
   "metadata": {},
   "source": [
    "Let's do the same as before by using the function cross_validate, that is, in a simpliest way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d607b74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00699449, 0.00858402, 0.00525188, 0.00499845, 0.00598884]),\n",
       " 'score_time': array([0.00528383, 0.0049994 , 0.00400114, 0.0030005 , 0.0059979 ]),\n",
       " 'test_neg_mean_squared_error': array([-2.77115937, -4.68929338, -2.76209053, -3.20828719, -2.03470369]),\n",
       " 'test_r2': array([0.83680303, 0.82562308, 0.89672437, 0.89333234, 0.91614896])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "scores = cross_validate(lin_reg, X_train, y_train, scoring = ['neg_mean_squared_error','r2'],cv = kf)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e547e",
   "metadata": {},
   "source": [
    "By comparing to the previous results when we did this same process more mannually, we can tell that they are the same. Now let's perform stratified cross validation. To make this possible we'll use other dataset in which the target is binary (1/0, yes/no, this/that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63851134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a678223",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_k_fold = StratifiedKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b78dae3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    24720\n",
       ">50K      7841\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = pd.read_csv('../data/census_income_data.csv')\n",
    "\n",
    "data_2['income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2888ab7",
   "metadata": {},
   "source": [
    "At first look we can notice that the label/target is umbalanced. So, in order to keep the proportion equal for every fold, we need to perform stratified k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e243bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration 0 (train)\n",
      "<=50K    19776\n",
      ">50K      6272\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 0 (test)\n",
      "<=50K    4944\n",
      ">50K     1569\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 1 (train)\n",
      "<=50K    19776\n",
      ">50K      6273\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 1 (test)\n",
      "<=50K    4944\n",
      ">50K     1568\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 2 (train)\n",
      "<=50K    19776\n",
      ">50K      6273\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 2 (test)\n",
      "<=50K    4944\n",
      ">50K     1568\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 3 (train)\n",
      "<=50K    19776\n",
      ">50K      6273\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 3 (test)\n",
      "<=50K    4944\n",
      ">50K     1568\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 4 (train)\n",
      "<=50K    19776\n",
      ">50K      6273\n",
      "Name: income, dtype: int64\n",
      "\n",
      "iteration 4 (test)\n",
      "<=50K    4944\n",
      ">50K     1568\n",
      "Name: income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for index, (train, test) in enumerate(st_k_fold.split(X = data_2.drop('income',axis=1), y = data_2['income'])):\n",
    "    print(\"\\niteration {0} (train)\\n{1}\".format(index,data_2.loc[train,'income'].value_counts()))\n",
    "    print(\"\\niteration {0} (test)\\n{1}\".format(index,data_2.loc[test,'income'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dadbf1",
   "metadata": {},
   "source": [
    "Now we can notice that the proportion of the label is preserved across all folds. \n",
    "<br></br>\n",
    "Finally, we're going to perform stratified group k-fold cross validation with the purpose of preserving the same proportion of the target variable and avoid biases caused by any category or group. In this case it is possible that the model could be biased by the person's education level.\n",
    "<br></br>\n",
    "By doing this, the model will be able to predict the outcome of people that belong to a brand new group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8148a1df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS-grad         10501\n",
       "Some-college     7291\n",
       "Bachelors        5355\n",
       "Masters          1723\n",
       "Assoc-voc        1382\n",
       "11th             1175\n",
       "Assoc-acdm       1067\n",
       "10th              933\n",
       "7th-8th           646\n",
       "Prof-school       576\n",
       "9th               514\n",
       "12th              433\n",
       "Doctorate         413\n",
       "5th-6th           333\n",
       "1st-4th           168\n",
       "Preschool          51\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e747737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5deba069",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_gr = StratifiedGroupKFold(n_splits = 5)\n",
    "groups = data_2['education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f42fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train:\n",
      "<=50K    15894\n",
      ">50K      6166\n",
      "Name: income, dtype: int64\n",
      "test:\n",
      "<=50K    8826\n",
      ">50K     1675\n",
      "Name: income, dtype: int64\n",
      "groups:\n",
      "HS-grad    10501\n",
      "Name: education, dtype: int64\n",
      "\n",
      " train:\n",
      "<=50K    18816\n",
      ">50K      6454\n",
      "Name: income, dtype: int64\n",
      "test:\n",
      "<=50K    5904\n",
      ">50K     1387\n",
      "Name: income, dtype: int64\n",
      "groups:\n",
      "Some-college    7291\n",
      "Name: education, dtype: int64\n",
      "\n",
      " train:\n",
      "<=50K    21565\n",
      ">50K      7031\n",
      "Name: income, dtype: int64\n",
      "test:\n",
      "<=50K    3155\n",
      ">50K      810\n",
      "Name: income, dtype: int64\n",
      "groups:\n",
      "11th           1175\n",
      "Assoc-acdm     1067\n",
      "7th-8th         646\n",
      "Prof-school     576\n",
      "5th-6th         333\n",
      "1st-4th         168\n",
      "Name: education, dtype: int64\n",
      "\n",
      " train:\n",
      "<=50K    21535\n",
      ">50K      5620\n",
      "Name: income, dtype: int64\n",
      "test:\n",
      "<=50K    3185\n",
      ">50K     2221\n",
      "Name: income, dtype: int64\n",
      "groups:\n",
      "Bachelors    5355\n",
      "Preschool      51\n",
      "Name: education, dtype: int64\n",
      "\n",
      " train:\n",
      "<=50K    21070\n",
      ">50K      6093\n",
      "Name: income, dtype: int64\n",
      "test:\n",
      "<=50K    3650\n",
      ">50K     1748\n",
      "Name: income, dtype: int64\n",
      "groups:\n",
      "Masters      1723\n",
      "Assoc-voc    1382\n",
      "10th          933\n",
      "9th           514\n",
      "12th          433\n",
      "Doctorate     413\n",
      "Name: education, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for index, (train, test) in enumerate(st_gr.split(X = data_2.drop('income',axis=1), y = data_2['income'], groups = groups)):\n",
    "    print(\"\\n train:\\n{0}\".format(data_2.loc[train,'income'].value_counts()))\n",
    "    print(\"test:\\n{0}\".format(data_2.loc[test,'income'].value_counts()))\n",
    "    print(\"groups:\\n{0}\".format(data_2.loc[test]['education'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53641690",
   "metadata": {},
   "source": [
    "Even though the amount of the target variable in both sets across the folds is not the same, as it was in previous cross validation types in most of the folds, the quantity in most folds is trying to be fair distributed (except for the first and third fold that the distribution in the test set is a little bit skewed compared to the other)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
